{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/roitraining/Rackspace-Python/blob/main/Rackspace_Python.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All of us have repetitive tasks in our work day.\n",
    "  * Some of these can be automated. \n",
    "  * We all understand how Excel macros work to allow automate tasks in a spreadsheet. \n",
    "* Python is an ideal choice because:\n",
    "    * It's one of the easiest languages to learn\n",
    "    * It's flexible enough to be used in a lot of different situations\n",
    "    * It's free, open source, cross platform and has an extensive library of community created add on modules known as packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use <a href=\"https://www.python.org\">Python</a> for automating tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some common use cases Python can be used to automate would be:\n",
    "* Data processing, transformation (ETL), engineering and analysis\n",
    "* Big Data procesing\n",
    "* Machine Learning and AI\n",
    "* OS and administrative installation and maintenance routines\n",
    "* Web Scraping\n",
    "* Internet of Things \n",
    "* Testing\n",
    "* Mocking\n",
    "* Many more ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's see a simple example of how to read the contents of a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegionID,RegionName\n",
      "1,North\n",
      "2,South\n",
      "3,East\n",
      "4,West\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"regions.txt\") as i:\n",
    "    data = i.read()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's improve on that a little to make it transform that data by uppercasing the regions and write it to a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGIONID,REGIONNAME\n",
      "1,NORTH\n",
      "2,SOUTH\n",
      "3,EAST\n",
      "4,WEST\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"regions.txt\") as i:\n",
    "    data = i.read()\n",
    "    with open(\"upper_regions.txt\", \"w\") as o:\n",
    "        o.write(data.upper())\n",
    "\n",
    "# Let's just see what it looks like\n",
    "with open(\"upper_regions.txt\") as o:\n",
    "    print(o.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can get much fancier than that using a common data processing module called <a href=\"https://pandas.pydata.org\">Pandas</a>.\n",
    "###### First we need to install this package and the <font color='blue' face=\"Courier New\" size=\"+3\">pip</font> utility will help us to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages/tk-0.1.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/joey/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joey/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TerritoryID</th>\n",
       "      <th>TerritoryName</th>\n",
       "      <th>RegionID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1581</td>\n",
       "      <td>Westboro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1730</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1833</td>\n",
       "      <td>Georgetow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2116</td>\n",
       "      <td>Boston</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2184</td>\n",
       "      <td>Braintree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2903</td>\n",
       "      <td>Providence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6897</td>\n",
       "      <td>Wilton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7960</td>\n",
       "      <td>Morristown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8837</td>\n",
       "      <td>Edison</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10019</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10038</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11747</td>\n",
       "      <td>Mellvile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14450</td>\n",
       "      <td>Fairport</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19713</td>\n",
       "      <td>Neward</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20852</td>\n",
       "      <td>Rockville</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27403</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27511</td>\n",
       "      <td>Cary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>40222</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TerritoryID TerritoryName  RegionID\n",
       "0          1581      Westboro         1\n",
       "1          1730       Bedford         1\n",
       "2          1833     Georgetow         1\n",
       "3          2116        Boston         1\n",
       "4          2139     Cambridge         1\n",
       "5          2184     Braintree         1\n",
       "6          2903    Providence         1\n",
       "9          6897        Wilton         1\n",
       "10         7960    Morristown         1\n",
       "11         8837        Edison         1\n",
       "12        10019      New York         1\n",
       "13        10038      New York         1\n",
       "14        11747      Mellvile         1\n",
       "15        14450      Fairport         1\n",
       "17        19713        Neward         1\n",
       "18        20852     Rockville         1\n",
       "19        27403    Greensboro         1\n",
       "20        27511          Cary         1\n",
       "26        40222    Louisville         1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file with headers\n",
    "df = pd.read_csv(\"data/territories_headers.csv\")\n",
    "\n",
    "# Filter based on a specific field (e.g., column \"Name\" with value \"John Doe\")\n",
    "filtered_df = df[df[\"RegionID\"] == 1]\n",
    "\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eventually we might get files that are so big they can't be processed on a single machine. \n",
    "* Fortunately people had this problem before us and solved it by creating a package like Pandas called <a href=\"https://spark.apache.org/docs/latest/api/python/index.html\">Spark</a> which is able to scale to multiple worker machines in a cluster and handle Big Data sized workloads of multiple TB and PB.\n",
    "* The code will look a little different but still pretty much the same concept "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TerritoryID</th>\n",
       "      <th>TerritoryName</th>\n",
       "      <th>RegionID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1581</td>\n",
       "      <td>Westboro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1730</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1833</td>\n",
       "      <td>Georgetow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2116</td>\n",
       "      <td>Boston</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2184</td>\n",
       "      <td>Braintree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2903</td>\n",
       "      <td>Providence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6897</td>\n",
       "      <td>Wilton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7960</td>\n",
       "      <td>Morristown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8837</td>\n",
       "      <td>Edison</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10019</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10038</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11747</td>\n",
       "      <td>Mellvile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14450</td>\n",
       "      <td>Fairport</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19713</td>\n",
       "      <td>Neward</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20852</td>\n",
       "      <td>Rockville</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27403</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27511</td>\n",
       "      <td>Cary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40222</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TerritoryID TerritoryName  RegionID\n",
       "0          1581      Westboro         1\n",
       "1          1730       Bedford         1\n",
       "2          1833     Georgetow         1\n",
       "3          2116        Boston         1\n",
       "4          2139     Cambridge         1\n",
       "5          2184     Braintree         1\n",
       "6          2903    Providence         1\n",
       "7          6897        Wilton         1\n",
       "8          7960    Morristown         1\n",
       "9          8837        Edison         1\n",
       "10        10019      New York         1\n",
       "11        10038      New York         1\n",
       "12        11747      Mellvile         1\n",
       "13        14450      Fairport         1\n",
       "14        19713        Neward         1\n",
       "15        20852     Rockville         1\n",
       "16        27403    Greensboro         1\n",
       "17        27511          Cary         1\n",
       "18        40222    Louisville         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"CSV Filtering\").getOrCreate()\n",
    "\n",
    "# Read CSV file with headers\n",
    "df = spark.read.csv(\"data/territories_headers.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Filter based on the RegionID field\n",
    "filtered_df = df.filter(F.col(\"RegionID\") == 1)\n",
    "\n",
    "filtered_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Once we've accumulated the multiple TB's of data and learned how to manipulate it with Big Data, the next step is often to use it for Machine Learning (ML)\n",
    "* ML is all about finding patterns in data to create a model that can predict future values based on the past patterns\n",
    "* Python is the dominant language in this field so you don't need to learn a whole new language, just some new packages and libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages/tk-0.1.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# load the CSV data\n",
    "data = pd.read_csv(\"data/credit_card_data.csv\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('day_of_week', OneHotEncoder(), ['day_of_week']),\n",
    "        ('store_type', OneHotEncoder(), ['store_type']),\n",
    "        ('online_or_inperson', OneHotEncoder(), ['online_or_inperson'])\n",
    "    ]\n",
    ")\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('classifier', LogisticRegression())])\n",
    "\n",
    "# Split into features and labels\n",
    "X = data.drop('is_valid', axis=1)\n",
    "y = data['is_valid']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "\n",
    "new_rows = pd.DataFrame([{\n",
    "    \"purchase_amount\": 500,\n",
    "    \"time_of_day\": 15,\n",
    "    \"day_of_week\": \"Tuesday\",\n",
    "    \"store_type\": \"Grocery\",\n",
    "    \"online_or_inperson\": \"In-Person\",\n",
    "}, {\n",
    "    \"purchase_amount\": 190,\n",
    "    \"time_of_day\": 9,\n",
    "    \"day_of_week\": \"Friday\",\n",
    "    \"store_type\": \"Restaurant\",\n",
    "    \"online_or_inperson\": \"Online\",\n",
    "}\n",
    "])\n",
    "\n",
    "prediction = model.predict(new_rows)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normally you'd have real data for this, but you can even uses Python and another community-built free library to generate the fake data I used to build this model.\n",
    "* This is sometimes called mocking, because we will create mock data.\n",
    "* Yet another automation task I can use Python for and of course there's a popular community package to help us do this called <a href=\"https://faker.readthedocs.io/en/master/\">Faker</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages/tk-0.1.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: faker in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (30.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /Users/joey/.local/lib/python3.12/site-packages (from faker) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from faker) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joey/.local/lib/python3.12/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "# Create a Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Generate 1000 rows of sample data\n",
    "data = []\n",
    "for _ in range(1000):\n",
    "    data.append({\n",
    "        'purchase_amount': fake.random_int(min=1, max=1000),\n",
    "        'day_of_week': fake.day_of_week(),\n",
    "        'time_of_day': fake.time(),\n",
    "        'time_of_day': fake.random_int(0, 23),\n",
    "        'online_or_inperson': fake.random_element(elements=['Online', 'In-Person']),\n",
    "        'is_valid': fake.random_element(elements=[0, 1])  # 0 for fraudulent, 1 for valid\n",
    "    })\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('data/credit_card_data2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's look at automating OS admin tasks\n",
    "* If you're using Windows you might use Powershell scripts to do this\n",
    "* For Linux you might use bash shell scripts\n",
    "* Python is better when the tasks are a little more complex\n",
    "* Also you can use the same scripts on any OS\n",
    "* In this example let's say we have a folder full of files and we want to identify all the ones that end with _archive and move them to another folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def move_archive_files(source_folder, destination_folder):\n",
    "  \"\"\"Moves all CSV files ending with '_archive' from the source folder to the destination folder.\"\"\"\n",
    "\n",
    "  for file_name in os.listdir(source_folder):\n",
    "    if file_name.endswith('_archive.csv'):\n",
    "      source_file = os.path.join(source_folder, file_name)\n",
    "      destination_file = os.path.join(destination_folder, file_name)\n",
    "      shutil.move(source_file, destination_file)\n",
    "      print(f\"Moved {file_name} to {destination_folder}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  if len(sys.argv) != 3:\n",
    "    print(\"Usage: python script.py <source_folder> <destination_folder>\")\n",
    "    sys.exit(1)\n",
    "\n",
    "  source_folder = sys.argv[1]\n",
    "  destination_folder = sys.argv[2]\n",
    "\n",
    "  move_archive_files(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sometimes you find a website that has some information on it that we'd like to automate. \n",
    "* Many times the website owner will make it easy to get that through a web service.\n",
    "* A lot of the time they don't, so we can go through a process known as web scraping to try to find that content in the web page and extract it.\n",
    "* There's many packages that can help to do this, but the most popular is called <a href=\"https://pypi.org/project/beautifulsoup4/\">Beautiful Soup</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages/tk-0.1.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: BeautifulSoup4 in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/joey/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from BeautifulSoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.306905 USD\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get('https://www.x-rates.com/calculator/?from=GBP&to=USD&amount=1')\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "part1 = soup.find(class_=\"ccOutputRslt\").get_text()\n",
    "print(part1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There's so many of these open source packages that do almost anything you might image.\n",
    "* There's a whole site that is a repository full of them that you can easily search through and see if some nice person has already solved your problem.\n",
    "* <a href=\"http://pypi.org\"> PyPi</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
